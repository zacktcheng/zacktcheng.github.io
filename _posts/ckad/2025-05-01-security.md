# Security

### Table of contents:
- [Security Primitives](#security-primitives)
- [KubeConfig](#kubeconfig)
- [API Groups](#api-groups)
- [Authorization](#authorization)

## Security Primitives

In the realm of Kubernetes, security is an essential aspect, especially as it serves as the preferred platform for hosting production grid applications. This particular lecture introduces various security primitives in
Kubernetes, setting the stage for a deeper dive in later sessions. The lecture initially emphasizes securing the hosts forming the cluster, advocating for measures such as disabling root access, disabling password-based
authentication, and enabling only SSH key-based authentication. It's crucial that the underlying infrastructure—whether physical or virtual—remains uncompromised to ensure the integrity of the Kubernetes environment.

The primary focus here is on Kubernetes-specific security, identifying potential risks and implementing measures to safeguard the cluster. A key component is the Kube API server, which is integral to Kubernetes operations and
is accessed via utilities like the kube control or direct API interactions. Controlling access to the API server stands as the initial line of defense, where decisions revolve around who can access the cluster and their
subsequent permissions. Authentication mechanisms can range from user IDs and passwords stored in static files, tokens, certificates, to external providers like LDAP, supplemented by service accounts for machines.

Authorization is managed through role-based access controls, aligning users into groups with specific permissions. This system is supported by other authorization modules, including attribute-based access control and node
authorizers. Secure communication across cluster components, such as the etcd cluster, kube controller, manager scheduler, API server, worker nodes, kubelet, and kube-proxy, is achieved via TLS encryption, which will be
explored fully in coming lectures.

Lastly, intra-cluster communication among applications, which is unrestricted by default, can be regulated using network policies. The implementation of these policies to manage access between applications within the cluster
is slated for examination in the network policy section, underscoring the comprehensive approach to securing Kubernetes environments.

### Authentication

Kubernetes does not natively manage user accounts, relying on external sources such as files with user details, certificates, or identity services like LDAP for this purpose. Service accounts, however, can be managed directly
using the Kubernetes API.

In Kubernetes, all user access is processed by the API server, which authenticates requests, whether they're made via the kube control tool or the API directly. Various authentication mechanisms are explored, including static
password and token files, certificates, and third-party protocols like LDAP and Kerberos. The simplest authentication method is using static files: a CSV file with columns for passwords, usernames, and user IDs can serve as
the user information source. This file is specified during kube-apiserver configuration, necessitating a server restart for changes to take effect—kubeadm tool users must modify the kube-apiserver pod definition file for
updates. Authentication is also possible with a static token file, substituting password with token and similarly passing the file details to the kube-apiserver. Notably, these methods of storing credentials in clear text are
insecure and not recommended, yet serve to introduce basic Kubernetes authentication concepts.

## KubeConfig

Initially, the method which Kubernetes authenticates user to access the clusters involves using a client certificate file and key to interact with the Kubernetes REST API through curl, specifying the cluster address
(my-kube-playground), and passing these files and the Certificate Authority (CA) certificate for authentication. For kubectl command usage, similar information is provided using options like server, client key, client
certificate, and certificate authority. However, to avoid repetitively typing these details, this information is consolidated into a kubeconfig file. By default, kubectl looks for this file in the .kube directory in the
user’s home directory, eliminating the need to specify the file path for each command.

The kubeconfig file, a YAML-formatted configuration, consists of three sections: clusters, users, and contexts. Clusters represent different environments or setups requiring access, like development or production. Users
denote various accounts accessing these clusters, each account potentially having distinct privileges. Contexts link users and clusters, defining which user accesses which cluster. This setup allows seamless switching
between users and clusters without manually specifying certificates and server addresses for each kubectl command.

The example provided illustrates configuring these sections. The "clusters" section specifies the cluster (my-kube-playground), including the server address and the CA certificate. The "users" section includes details
about user credentials, like client certificates and keys. The "contexts" section connects a user to a cluster, for instance, pairing my-kube-admin user with the my-kube-playground cluster. By defining a "current-context,"
users set a default starting point for commands. The kubectl tool allows manipulation of kubeconfig files via commands like kubectl config view and kubectl config use-context, enabling users to adjust the current context
for different tasks.

The file structure supports multiple clusters and namespaces, with support for configuring specific namespaces within these contexts. Certificates can be incorporated by specifying paths or using base64 encoding for
certificate data, enhancing flexibility in managing certificate information. This setup streamlines user and cluster management, easing the administrative burden by allowing predefined access configurations and seamless
context switching.

## API Groups

Understanding API groups in Kubernetes is crucial for interacting with the Kubernetes API, which facilitates communication with the Kube API server. This text discusses how all cluster operations involve the API server,
accessed either through utilities like kubectl or directly via REST calls. For example, you can check the cluster version by connecting to the master's address followed by the default port 6443 and the appropriate API
version. Similarly, accessing specific paths like /api/v1/pods retrieves the list of pods. The focus here is on the Kubernetes API groups, categorized by purpose, such as APIs for cluster version, health monitoring,
metrics, logs, etc.

The Kubernetes API consists of core groups and named groups. The core group handles essential functionalities like namespaces, pods, replication controllers, and services. Named groups cater to specific needs with more
organization, providing APIs for apps, extensions, networking, storage, authentication, and authorization. These groups contain resources such as deployments, replica sets, network policies, and certificate requests. Each
resource has actions, known as verbs, enabling tasks like listing deployments, creating or deleting them, and updating or watching their status. The Kubernetes API reference page details each object’s group, and objects
can be viewed within your cluster at the API server's port.

Accessing the API directly via tools like curl requires proper authentication. You need to pass certificate files using command-line options to authenticate requests. Alternatively, by launching a kube control proxy client
using the kubectl proxy command, a local proxy service starts on port 8001, automatically using Kube config credentials to access the cluster, removing the need for command-line authorization in curl commands. This proxy
serves as a bridge to view all available APIs.

An important distinction arises between kube proxy and kube control proxy—while the former facilitates inter-node connectivity in a cluster, the latter is an HTTP proxy service initiated by the kubectl utility to interact
with the API server. In summary, Kubernetes resources are organized under different API groups, each with unique resources and actions, helping streamline the management and authorization of cluster operations. Future
sections will delve into using API groups for configuring user access and permissions.

## Authorization

Authorization is a crucial aspect of managing a Kubernetes cluster, ensuring controlled access for various users and applications. Initially, as a cluster administrator, you have the ability to perform all operations, such
as viewing, creating, or deleting objects like pods and nodes. However, as more users and applications, including developers, testers, and continuous integration tools like Jenkins, access the cluster, it's essential to
create user accounts with different access levels using usernames, passwords, tokens, or service accounts.

The goal is to enforce access control, limiting the abilities of non-administrative users. For instance, developers shouldn't modify cluster configurations like adding or deleting nodes; instead, their access should be
restricted to deploying applications. Authorization also extends to service accounts, which should only have the minimum permissions required to perform their operations. When sharing a cluster among different teams or
organizations, logical partitioning through namespaces ensures that users access only their designated areas.

Kubernetes supports various authorization mechanisms such as node authorization, attribute-based authorization, role-based authorization, and Webhook. Node authorization is managed by a special authorizer for kubelets
accessing the API server for cluster management tasks. Attribute-based authorization maps users or groups to permissions via policy files, but it's cumbersome to manage due to manual updates and server restarts required
when changes are made.

Role-based access control (RBAC) simplifies access management by defining roles with specific permissions and associating them with users or groups. This approach allows for efficient updates; modifying a role automatically
updates access for all associated users. RBAC provides a standardized method for managing access within Kubernetes clusters, and further detailed exploration of RBAC can enhance understanding.

For those who prefer external management of authorization, third-party tools like Open Policy Agent can be integrated. Kubernetes would query such tools to decide user access, thus outsourcing authorization control.
Additionally, Kubernetes offers 'always allow' and 'always deny' modes: 'always allow' grants access without checks, while 'always deny' blocks all requests. The authorization mode is configured via the Kube API server,
defaulting to 'always allow' if unspecified. Multiple modes can be set, processed sequentially, and requests are authorized based on their checks until one approves the request, granting access immediately. This mechanism
ensures flexible yet controlled authentication environments.
