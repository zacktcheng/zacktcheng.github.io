# Chat Completion Basics

## Table of contents
- [Project Structure intro](#project-structure-intro)
- [Chat completion](#chat-completion)
- [Conversation states](#conversation-states)

## Project structure intro
### Key files
- tsconfig.json: A standard TypeScript configuration file that has been slightly modified to allow for top-level awaits, making scripts cleaner.
- package.json: A standard file listing dependencies. For the introductory project, the dependencies include typescript (as a dev dependency), openai, and dotenv.
- app.ts: The main script file where code for the lecture will be written.
- .env: A file used to store API keys and other environment variables.
  - The project uses the dotenv package to manage environment variables and API keys, which are stored in the .env file.
  - Once loaded, you can access the variables using `process.env.<VARIABLE_NAME>`. This ensures that sensitive information is not hard-coded into the application.

### How to install dependencies
Navigate into the project folder using the command `cd intro`.
Run `npm install` to automatically install the required packages.

### How to execute the script
The instructor uses tsx, a command-line tool, to execute TypeScript files directly without a separate compilation step.   
To run the main script, the command is `npx tsx app.ts`.

## Chat completion
### Setup
- Environment Variables: First, you must create a .env file inside the intro project folder to store your OpenAI API key. This file is not tracked in Git to protect sensitive information.  
- Install the SDK: The openai package from NPM is used to interact with the API. You can install it by running npm install openai if you don't already have it. The instructor assumes this is already done if you've cloned the repository.

### Initializing the OpenAI Client
```
import OpenAI from "openai";

// ... other code

const openai = new OpenAI();
```
The SDK automatically looks for the OPENAI_API_KEY environment variable, so you do not need to pass your API key directly to the client constructor.

### Creating a Chat Completion
The main focus of the lesson is creating a chat completion, which is a type of request used to build conversational AI. The tutorial demonstrates how to use the openai.chat.completions.create method with the following key parameters:
- model: The AI model to use. The recommended and most accessible model for the course is gpt-3.5-turbo.
- temperature: A value between 0 and 1 that controls the creativity of the AI's response. A value of 0 is best for factual responses, while higher values lead to more creative and varied output.
- messages: An array of message objects that represents the conversation history. Each message object has a role (either "user", "assistant", or "system") and content.

Example code:
```
{
  "role": "user",
  "content": "My name is Ariel. Greet me."
}
```

Here is my script example:
```
import { AzureOpenAI } from "openai";
import { endpoint, apiKey, apiVersion, model } from './clientConfig';

const client = new AzureOpenAI({
  endpoint,
  apiKey,
  apiVersion,
});

const response = await client.chat.completions.create({
  model,
  messages: [
    {
      role: 'user',
      content: 'Who is the first president of the United States of America?'
    }
  ],
  temperature: 0,
});

console.log(response.choices[0].message)
```

## Conversation states
###Managing Conversation Context
When building a chatbot, you must manually maintain the full history of the conversation to provide context to the AI. The OpenAI API works by receiving an array of messages with each request. This array contains all previous messages in the conversation, allowing the AI to understand what has been discussed so far.
Each message in this array is an object with a defined role and content:
- system: A message that gives the AI general guidelines for how to behave. For example, a system message could instruct the AI to be rude or helpful.
- user: The message sent by the person interacting with the AI.
- assistant: The response generated by the AI.

Here is my script example:
```
import openai, { AzureOpenAI } from 'openai';
import { endpoint, apiKey, apiVersion, model } from './clientConfig'; 
import { createInterface } from 'readline';

const client = new AzureOpenAI({
  endpoint,
  apiKey,
  apiVersion,
});

const conversation: openai.Chat.Completions.ChatCompletionMessageParam[] = [
  {
    role: 'system',
    content: 'You are an incredibly rude AI chatbot. Every single message you send is rude.'
  }
];

const createChatCompletion = async () => {
  const response = await client.chat.completions.create({
    messages: conversation,
    model,
    temperature: 0
  });
  const { role, content } = response.choices[0].message;
  conversation.push({ role, content });
  console.log(`[${role}]`, content);
}

const io = createInterface({
  input: process.stdin,
  output: process.stdout
});

io.on('line',async (input: string) => {
  conversation.push({
    role: 'user',
    content: input
  });
  console.log('[user]', input);
  await createChatCompletion();
})

console.log('Enter a message for rudeAI.');
```
